{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO+9p2FWtpgaEI+syz7izF3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasterNathan01/4106/blob/main/WatersNathan_801283595_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PROBLEM 1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#English to French translation dataset\n",
        "english_to_french = [\n",
        "\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\"),\n",
        "    (\"They ride bicycles\", \"Ils font du vélo\"),\n",
        "    (\"The coffee is hot\", \"Le café est chaud\"),\n",
        "    (\"She wears glasses\", \"Elle porte des lunettes\"),\n",
        "    (\"We visit our grandparents\", \"Nous rendons visite à nos grands-parents\"),\n",
        "    (\"He plays the guitar\", \"Il joue de la guitare\"),\n",
        "    (\"They go shopping\", \"Ils font du shopping\"),\n",
        "    (\"The teacher explains the lesson\", \"Le professeur explique la leçon\"),\n",
        "    (\"She takes the train to work\", \"Elle prend le train pour aller au travail\"),\n",
        "    (\"We bake cookies\", \"Nous faisons des biscuits\"),\n",
        "    (\"He washes his hands\", \"Il se lave les mains\"),\n",
        "    (\"They enjoy the sunset\", \"Ils apprécient le coucher du soleil\"),\n",
        "    (\"The river flows calmly\", \"La rivière coule calmement\"),\n",
        "    (\"She feeds the cat\", \"Elle nourrit le chat\"),\n",
        "    (\"We visit the museum\", \"Nous visitons le musée\"),\n",
        "    (\"He fixes his bicycle\", \"Il répare son vélo\"),\n",
        "    (\"They paint the walls\", \"Ils peignent les murs\"),\n",
        "    (\"The baby sleeps peacefully\", \"Le bébé dort paisiblement\"),\n",
        "    (\"She ties her shoelaces\", \"Elle attache ses lacets\"),\n",
        "    (\"We climb the stairs\", \"Nous montons les escaliers\"),\n",
        "    (\"He shaves in the morning\", \"Il se rase le matin\"),\n",
        "    (\"They set the table\", \"Ils mettent la table\"),\n",
        "    (\"The airplane takes off\", \"L'avion décolle\"),\n",
        "    (\"She waters the plants\", \"Elle arrose les plantes\"),\n",
        "    (\"We practice yoga\", \"Nous pratiquons le yoga\"),\n",
        "    (\"He turns off the light\", \"Il éteint la lumière\"),\n",
        "    (\"They play video games\", \"Ils jouent aux jeux vidéo\"),\n",
        "    (\"The soup smells delicious\", \"La soupe sent délicieusement bon\"),\n",
        "    (\"She locks the door\", \"Elle ferme la porte à clé\"),\n",
        "    (\"We enjoy a picnic\", \"Nous profitons d'un pique-nique\"),\n",
        "    (\"He checks his email\", \"Il vérifie ses emails\"),\n",
        "    (\"They go to the gym\", \"Ils vont à la salle de sport\"),\n",
        "    (\"The moon shines brightly\", \"La lune brille intensément\"),\n",
        "    (\"She catches the bus\", \"Elle attrape le bus\"),\n",
        "    (\"We greet our neighbors\", \"Nous saluons nos voisins\"),\n",
        "    (\"He combs his hair\", \"Il se peigne les cheveux\"),\n",
        "    (\"They wave goodbye\", \"Ils font un signe d'adieu\")\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#special tokens\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "#word-to-index\n",
        "word_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token}\n",
        "for eng, fr in english_to_french:\n",
        "    for word in eng.split() + fr.split():\n",
        "        if word not in word_to_index:\n",
        "            word_to_index[word] = len(word_to_index)\n",
        "\n",
        "index_to_word = {i: word for word, i in word_to_index.items()}\n",
        "\n",
        "#sentences to indexed sequences\n",
        "def sentence_to_indices(sentence, vocab):\n",
        "    return [vocab['SOS']] + [vocab.get(word, vocab['EOS']) for word in sentence.split()] + [vocab['EOS']]\n",
        "\n",
        "#dataset class\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, vocab):\n",
        "        self.dataset = dataset\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        eng_sentence, fr_sentence = self.dataset[idx]\n",
        "        return {\n",
        "            'eng': torch.tensor(sentence_to_indices(eng_sentence, self.vocab), dtype=torch.long),\n",
        "            'fr': torch.tensor(sentence_to_indices(fr_sentence, self.vocab), dtype=torch.long)\n",
        "        }\n",
        "\n",
        "#dataloaders\n",
        "dataset = TranslationDataset(english_to_french, word_to_index)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "#encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "#decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.softmax(self.fc(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "#model\n",
        "hidden_size = 256\n",
        "input_size = output_size = len(word_to_index)\n",
        "encoder = Encoder(input_size, hidden_size).to(device)\n",
        "decoder = Decoder(hidden_size, output_size).to(device)\n",
        "\n",
        "#training\n",
        "learning_rate = 0.01\n",
        "criterion = nn.NLLLoss()\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "n_epochs = 50\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        _, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "        if decoder_input.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "#train model\n",
        "for epoch in range(n_epochs):\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "        pass\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_tensor, target_tensor = batch['eng'][0].to(device), batch['fr'][0].to(device)\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        total_loss += loss\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "#translation\n",
        "def translate(sentence, model, vocab):\n",
        "    model.eval()\n",
        "    indices = sentence_to_indices(sentence, vocab)\n",
        "    tensor = torch.LongTensor(indices).unsqueeze(0).to(device)\n",
        "    tensor = tensor.view(-1, 1)\n",
        "    embedded = encoder.embedding(tensor)\n",
        "    _, hidden = encoder.gru(embedded, encoder.init_hidden())\n",
        "    input = torch.tensor([SOS_token], device=device)\n",
        "    result = []\n",
        "    for _ in range(10):\n",
        "        output, hidden = decoder(input, hidden)\n",
        "        token = output.argmax(1).item()\n",
        "        if token == EOS_token:\n",
        "            break\n",
        "        result.append(index_to_word.get(token, '?'))\n",
        "        input = torch.tensor([token], device=device)\n",
        "    return ' '.join(result)\n",
        "\n",
        "# Test translation\n",
        "print(\"Final Validation Results:\")\n",
        "print(f\"Loss: {total_loss / len(dataloader):.4f}\")\n",
        "print(\"Example translations:\")\n",
        "for sentence in [\"They travel around the world\", \"The baby cries\", \"We visit our grandparents\", \"He checks his email\", \"I am cold\"]:\n",
        "    print(f\"{sentence} -> {translate(sentence, encoder, word_to_index)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg6NbaeAsbjS",
        "outputId": "d2acadc0-741f-4c46-e6f5-bf5349c0c46f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 3.0490\n",
            "Epoch 2, Loss: 2.6942\n",
            "Epoch 3, Loss: 2.7231\n",
            "Epoch 4, Loss: 2.8586\n",
            "Epoch 5, Loss: 2.8554\n",
            "Epoch 6, Loss: 2.8340\n",
            "Epoch 7, Loss: 2.7349\n",
            "Epoch 8, Loss: 2.6661\n",
            "Epoch 9, Loss: 2.5687\n",
            "Epoch 10, Loss: 2.5145\n",
            "Epoch 11, Loss: 2.3607\n",
            "Epoch 12, Loss: 2.2893\n",
            "Epoch 13, Loss: 2.2520\n",
            "Epoch 14, Loss: 2.0821\n",
            "Epoch 15, Loss: 1.9862\n",
            "Epoch 16, Loss: 1.9448\n",
            "Epoch 17, Loss: 1.8186\n",
            "Epoch 18, Loss: 1.7698\n",
            "Epoch 19, Loss: 1.6991\n",
            "Epoch 20, Loss: 1.6111\n",
            "Epoch 21, Loss: 1.4910\n",
            "Epoch 22, Loss: 1.3916\n",
            "Epoch 23, Loss: 1.3103\n",
            "Epoch 24, Loss: 1.2094\n",
            "Epoch 25, Loss: 1.0535\n",
            "Epoch 26, Loss: 0.9594\n",
            "Epoch 27, Loss: 0.8055\n",
            "Epoch 28, Loss: 0.7089\n",
            "Epoch 29, Loss: 0.6499\n",
            "Epoch 30, Loss: 0.5727\n",
            "Epoch 31, Loss: 0.4260\n",
            "Epoch 32, Loss: 0.3852\n",
            "Epoch 33, Loss: 0.2936\n",
            "Epoch 34, Loss: 0.2713\n",
            "Epoch 35, Loss: 0.2309\n",
            "Epoch 36, Loss: 0.2054\n",
            "Epoch 37, Loss: 0.1855\n",
            "Epoch 38, Loss: 0.1682\n",
            "Epoch 39, Loss: 0.1403\n",
            "Epoch 40, Loss: 0.1191\n",
            "Epoch 41, Loss: 0.1109\n",
            "Epoch 42, Loss: 0.0995\n",
            "Epoch 43, Loss: 0.0830\n",
            "Epoch 44, Loss: 0.0822\n",
            "Epoch 45, Loss: 0.0732\n",
            "Epoch 46, Loss: 0.0669\n",
            "Epoch 47, Loss: 0.0607\n",
            "Epoch 48, Loss: 0.0561\n",
            "Epoch 49, Loss: 0.0541\n",
            "Epoch 50, Loss: 0.0498\n",
            "Final Validation Results:\n",
            "Loss: 0.0498\n",
            "Example translations:\n",
            "They travel around the world -> SOS Ils voyagent autour du monde\n",
            "The baby cries -> SOS Le bébé pleure\n",
            "We visit our grandparents -> SOS Nous rendons visite à nos grands-parents\n",
            "He checks his email -> SOS Il vérifie ses emails\n",
            "I am cold -> SOS J'ai froid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Special tokens\n",
        "START_TOKEN = 0\n",
        "END_TOKEN = 1\n",
        "\n",
        "sentence_pairs = english_to_french\n",
        "\n",
        "word_to_id = {\"SOS\": START_TOKEN, \"EOS\": END_TOKEN}\n",
        "for pair in sentence_pairs:\n",
        "    for word in pair[0].split() + pair[1].split():\n",
        "        if word not in word_to_id:\n",
        "            word_to_id[word] = len(word_to_id)\n",
        "\n",
        "id_to_word = {i: word for word, i in word_to_id.items()}\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, word_to_id):\n",
        "        self.dataset = dataset\n",
        "        self.word_to_id = word_to_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        source_sentence, target_sentence = self.dataset[idx]\n",
        "        source_indices = [self.word_to_id[word] for word in source_sentence.split()] + [END_TOKEN]\n",
        "        target_indices = [self.word_to_id[word] for word in target_sentence.split()] + [END_TOKEN]\n",
        "        return torch.tensor(source_indices, dtype=torch.long), torch.tensor(target_indices, dtype=torch.long)\n",
        "\n",
        "max_seq_length = 14\n",
        "translation_data = TranslationDataset(sentence_pairs, word_to_id)\n",
        "data_loader = DataLoader(translation_data, batch_size=1, shuffle=True)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        self.gru = nn.GRU(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, input_seq, hidden_state):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output, hidden_state = self.gru(embedded, hidden_state)\n",
        "        return output, hidden_state\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_dim, device=device)\n",
        "\n",
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, vocab_size, max_seq_length=14, dropout_rate=0.1):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        self.attn = nn.Linear(hidden_dim * 2, max_seq_length)\n",
        "        self.attn_combine = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.gru = nn.GRU(hidden_dim, hidden_dim)\n",
        "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden_state, encoder_outputs):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = torch.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden_state[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = torch.relu(output)\n",
        "        output, hidden_state = self.gru(output, hidden_state)\n",
        "\n",
        "        output = torch.log_softmax(self.output_layer(output[0]), dim=1)\n",
        "        return output, hidden_state, attn_weights\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_dim, device=device)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "hidden_dim = 256\n",
        "\n",
        "encoder = Encoder(vocab_size=vocab_size, hidden_dim=hidden_dim).to(device)\n",
        "decoder = AttentionDecoder(hidden_dim=hidden_dim, vocab_size=vocab_size).to(device)\n",
        "\n",
        "learning_rate = 0.008\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "n_epochs = 45\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for input_tensor, target_tensor in data_loader:\n",
        "        input_tensor = input_tensor[0].to(device)\n",
        "        target_tensor = target_tensor[0].to(device)\n",
        "\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        input_length = input_tensor.size(0)\n",
        "        target_length = target_tensor.size(0)\n",
        "\n",
        "        loss = 0\n",
        "        encoder_outputs = torch.zeros(max_seq_length, hidden_dim, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[START_TOKEN]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "            if decoder_input.item() == END_TOKEN:\n",
        "                break\n",
        "\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() / target_length\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {total_loss / len(data_loader)}')\n",
        "\n",
        "final_loss = total_loss / len(data_loader)\n",
        "print(f'Final Validation Loss: {final_loss}')\n",
        "\n",
        "# Print example translations\n",
        "for i, (input_tensor, target_tensor) in enumerate(data_loader):\n",
        "    if i >= 5:\n",
        "        break\n",
        "    input_sentence = ' '.join([id_to_word[idx.item()] for idx in input_tensor[0] if idx.item() not in (START_TOKEN, END_TOKEN)])\n",
        "    target_sentence = ' '.join([id_to_word[idx.item()] for idx in target_tensor[0] if idx.item() not in (START_TOKEN, END_TOKEN)])\n",
        "    print(f'Input: {input_sentence} -> Target: {target_sentence}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_7lbMGU2N9g",
        "outputId": "e3e998ad-1e74-4614-8aaa-b409dacfcef7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 3.927512259308518\n",
            "Epoch 5, Loss: 3.2505397310617314\n",
            "Epoch 10, Loss: 2.7059175591636935\n",
            "Epoch 15, Loss: 2.1461742696944275\n",
            "Epoch 20, Loss: 1.5870833926596726\n",
            "Epoch 25, Loss: 1.0509329870822544\n",
            "Epoch 30, Loss: 0.5413270741801598\n",
            "Epoch 35, Loss: 0.25342202358809157\n",
            "Epoch 40, Loss: 0.13523494069316538\n",
            "Final Validation Loss: 0.09010129357459322\n",
            "Input: She ties her shoelaces -> Target: Elle attache ses lacets\n",
            "Input: I am cold -> Target: J'ai froid\n",
            "Input: The dog barks loudly -> Target: Le chien aboie bruyamment\n",
            "Input: The cat is sleeping -> Target: Le chat dort\n",
            "Input: He climbs the mountain -> Target: Il gravit la montagne\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PROBLEM 3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# French to English translation dataset\n",
        "french_to_english = [\n",
        "    (\"J'ai froid\", \"I am cold\"),\n",
        "    (\"Tu es fatigué\", \"You are tired\"),\n",
        "    (\"Il a faim\", \"He is hungry\"),\n",
        "    (\"Elle est heureuse\", \"She is happy\"),\n",
        "    (\"Nous sommes amis\", \"We are friends\"),\n",
        "    (\"Ils sont étudiants\", \"They are students\"),\n",
        "    (\"Le chat dort\", \"The cat is sleeping\"),\n",
        "    (\"Le soleil brille\", \"The sun is shining\"),\n",
        "    (\"Nous aimons la musique\", \"We love music\"),\n",
        "    (\"Elle parle français couramment\", \"She speaks French fluently\"),\n",
        "]\n",
        "\n",
        "# Special tokens\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "# Word-to-index mapping\n",
        "word_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token}\n",
        "for fr, eng in french_to_english:\n",
        "    for word in fr.split() + eng.split():\n",
        "        if word not in word_to_index:\n",
        "            word_to_index[word] = len(word_to_index)\n",
        "\n",
        "index_to_word = {i: word for word, i in word_to_index.items()}\n",
        "\n",
        "# Convert sentences to indexed sequences\n",
        "def sentence_to_indices(sentence, vocab):\n",
        "    return [vocab['SOS']] + [vocab.get(word, vocab['EOS']) for word in sentence.split()] + [vocab['EOS']]\n",
        "\n",
        "# Dataset class\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, vocab):\n",
        "        self.dataset = dataset\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fr_sentence, eng_sentence = self.dataset[idx]\n",
        "        return {\n",
        "            'fr': torch.tensor(sentence_to_indices(fr_sentence, self.vocab), dtype=torch.long),\n",
        "            'eng': torch.tensor(sentence_to_indices(eng_sentence, self.vocab), dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# DataLoaders\n",
        "dataset = TranslationDataset(french_to_english, word_to_index)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Encoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "# Decoder model\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.softmax(self.fc(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "# Model setup\n",
        "hidden_size = 256\n",
        "input_size = output_size = len(word_to_index)\n",
        "encoder = Encoder(input_size, hidden_size).to(device)\n",
        "decoder = Decoder(hidden_size, output_size).to(device)\n",
        "\n",
        "# Training setup\n",
        "learning_rate = 0.01\n",
        "criterion = nn.NLLLoss()\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "n_epochs = 50\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        _, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "        if decoder_input.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "# Train model\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_tensor, target_tensor = batch['fr'][0].to(device), batch['eng'][0].to(device)\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        total_loss += loss\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "# Translation function\n",
        "def translate(sentence, model, vocab):\n",
        "    model.eval()\n",
        "    indices = sentence_to_indices(sentence, vocab)\n",
        "    tensor = torch.LongTensor(indices).unsqueeze(0).to(device)\n",
        "    tensor = tensor.view(-1, 1)\n",
        "    embedded = encoder.embedding(tensor)\n",
        "    _, hidden = encoder.gru(embedded, encoder.init_hidden())\n",
        "    input = torch.tensor([SOS_token], device=device)\n",
        "    result = []\n",
        "    for _ in range(10):\n",
        "        output, hidden = decoder(input, hidden)\n",
        "        token = output.argmax(1).item()\n",
        "        if token == EOS_token:\n",
        "            break\n",
        "        result.append(index_to_word.get(token, '?'))\n",
        "        input = torch.tensor([token], device=device)\n",
        "    return ' '.join(result)\n",
        "\n",
        "# Test translation\n",
        "print(\"Final Validation Results:\")\n",
        "print(f\"Loss: {total_loss / len(dataloader):.4f}\")\n",
        "print(\"Example translations:\")\n",
        "for sentence in [\"J'ai froid\", \"Le chat dort\", \"Nous aimons la musique\", \"Elle parle français couramment\", \"Ils voyagent autour du monde\"]:\n",
        "    print(f\"{sentence} -> {translate(sentence, encoder, word_to_index)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5jMkxGnZU1l",
        "outputId": "5dfd7d28-b116-4f8b-bab3-8caff9308077"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 3.2952\n",
            "Epoch 2, Loss: 2.6979\n",
            "Epoch 3, Loss: 2.5231\n",
            "Epoch 4, Loss: 2.2457\n",
            "Epoch 5, Loss: 2.1692\n",
            "Epoch 6, Loss: 1.9098\n",
            "Epoch 7, Loss: 2.2307\n",
            "Epoch 8, Loss: 2.1738\n",
            "Epoch 9, Loss: 1.8137\n",
            "Epoch 10, Loss: 1.9108\n",
            "Epoch 11, Loss: 1.8099\n",
            "Epoch 12, Loss: 1.6560\n",
            "Epoch 13, Loss: 1.8424\n",
            "Epoch 14, Loss: 1.8090\n",
            "Epoch 15, Loss: 1.7178\n",
            "Epoch 16, Loss: 1.6208\n",
            "Epoch 17, Loss: 1.5646\n",
            "Epoch 18, Loss: 1.6994\n",
            "Epoch 19, Loss: 1.5743\n",
            "Epoch 20, Loss: 1.4124\n",
            "Epoch 21, Loss: 1.4211\n",
            "Epoch 22, Loss: 1.5788\n",
            "Epoch 23, Loss: 1.3978\n",
            "Epoch 24, Loss: 1.3991\n",
            "Epoch 25, Loss: 1.3497\n",
            "Epoch 26, Loss: 1.2560\n",
            "Epoch 27, Loss: 1.2553\n",
            "Epoch 28, Loss: 1.1528\n",
            "Epoch 29, Loss: 1.0247\n",
            "Epoch 30, Loss: 1.0104\n",
            "Epoch 31, Loss: 0.8749\n",
            "Epoch 32, Loss: 0.8456\n",
            "Epoch 33, Loss: 0.9597\n",
            "Epoch 34, Loss: 0.6807\n",
            "Epoch 35, Loss: 0.6593\n",
            "Epoch 36, Loss: 0.5801\n",
            "Epoch 37, Loss: 0.5598\n",
            "Epoch 38, Loss: 0.5155\n",
            "Epoch 39, Loss: 0.4483\n",
            "Epoch 40, Loss: 0.3914\n",
            "Epoch 41, Loss: 0.3781\n",
            "Epoch 42, Loss: 0.3370\n",
            "Epoch 43, Loss: 0.2956\n",
            "Epoch 44, Loss: 0.2634\n",
            "Epoch 45, Loss: 0.2350\n",
            "Epoch 46, Loss: 0.2147\n",
            "Epoch 47, Loss: 0.1953\n",
            "Epoch 48, Loss: 0.1810\n",
            "Epoch 49, Loss: 0.1669\n",
            "Epoch 50, Loss: 0.1534\n",
            "Final Validation Results:\n",
            "Loss: 0.1534\n",
            "Example translations:\n",
            "J'ai froid -> SOS I am cold\n",
            "Le chat dort -> SOS The cat is sleeping\n",
            "Nous aimons la musique -> SOS We love music\n",
            "Elle parle français couramment -> SOS She speaks French fluently\n",
            "Ils voyagent autour du monde -> SOS SOS The cat is sleeping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 4\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Special tokens\n",
        "START_TOKEN = 0\n",
        "END_TOKEN = 1\n",
        "\n",
        "sentence_pairs = french_to_english\n",
        "\n",
        "word_to_id = {\"SOS\": START_TOKEN, \"EOS\": END_TOKEN}\n",
        "for pair in sentence_pairs:\n",
        "    for word in pair[0].split() + pair[1].split():\n",
        "        if word not in word_to_id:\n",
        "            word_to_id[word] = len(word_to_id)\n",
        "\n",
        "id_to_word = {i: word for word, i in word_to_id.items()}\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, word_to_id):\n",
        "        self.dataset = dataset\n",
        "        self.word_to_id = word_to_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        source_sentence, target_sentence = self.dataset[idx]\n",
        "        source_indices = [self.word_to_id[word] for word in source_sentence.split()] + [END_TOKEN]\n",
        "        target_indices = [self.word_to_id[word] for word in target_sentence.split()] + [END_TOKEN]\n",
        "        return torch.tensor(source_indices, dtype=torch.long), torch.tensor(target_indices, dtype=torch.long)\n",
        "\n",
        "max_seq_length = 14\n",
        "translation_data = TranslationDataset(sentence_pairs, word_to_id)\n",
        "data_loader = DataLoader(translation_data, batch_size=1, shuffle=True)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        self.gru = nn.GRU(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, input_seq, hidden_state):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output, hidden_state = self.gru(embedded, hidden_state)\n",
        "        return output, hidden_state\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_dim, device=device)\n",
        "\n",
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, vocab_size, max_seq_length=14, dropout_rate=0.1):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        self.attn = nn.Linear(hidden_dim * 2, max_seq_length)\n",
        "        self.attn_combine = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.gru = nn.GRU(hidden_dim, hidden_dim)\n",
        "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden_state, encoder_outputs):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = torch.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden_state[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = torch.relu(output)\n",
        "        output, hidden_state = self.gru(output, hidden_state)\n",
        "\n",
        "        output = torch.log_softmax(self.output_layer(output[0]), dim=1)\n",
        "        return output, hidden_state, attn_weights\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_dim, device=device)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "hidden_dim = 256\n",
        "\n",
        "encoder = Encoder(vocab_size=vocab_size, hidden_dim=hidden_dim).to(device)\n",
        "decoder = AttentionDecoder(hidden_dim=hidden_dim, vocab_size=vocab_size).to(device)\n",
        "\n",
        "learning_rate = 0.008\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "n_epochs = 45\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for input_tensor, target_tensor in data_loader:\n",
        "        input_tensor = input_tensor[0].to(device)\n",
        "        target_tensor = target_tensor[0].to(device)\n",
        "\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        input_length = input_tensor.size(0)\n",
        "        target_length = target_tensor.size(0)\n",
        "\n",
        "        loss = 0\n",
        "        encoder_outputs = torch.zeros(max_seq_length, hidden_dim, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[START_TOKEN]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "            if decoder_input.item() == END_TOKEN:\n",
        "                break\n",
        "\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() / target_length\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {total_loss / len(data_loader)}')\n",
        "\n",
        "final_loss = total_loss / len(data_loader)\n",
        "print(f'Final Validation Loss: {final_loss}')\n",
        "\n",
        "# Print example translations\n",
        "for i, (input_tensor, target_tensor) in enumerate(data_loader):\n",
        "    if i >= 5:\n",
        "        break\n",
        "    input_sentence = ' '.join([id_to_word[idx.item()] for idx in input_tensor[0] if idx.item() not in (START_TOKEN, END_TOKEN)])\n",
        "    target_sentence = ' '.join([id_to_word[idx.item()] for idx in target_tensor[0] if idx.item() not in (START_TOKEN, END_TOKEN)])\n",
        "    print(f'Input: {input_sentence} -> Target: {target_sentence}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9v0gagocu-L",
        "outputId": "e3ab4243-9df1-4246-9c5c-914c3b77922e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 3.0639185428619387\n",
            "Epoch 5, Loss: 2.735391492843628\n",
            "Epoch 10, Loss: 2.3112361669540404\n",
            "Epoch 15, Loss: 1.8466356325149538\n",
            "Epoch 20, Loss: 1.7071329712867738\n",
            "Epoch 25, Loss: 1.497920732498169\n",
            "Epoch 30, Loss: 1.1030938243865964\n",
            "Epoch 35, Loss: 0.8304978036880494\n",
            "Epoch 40, Loss: 0.5476467430591583\n",
            "Final Validation Loss: 0.388521776497364\n",
            "Input: Ils sont étudiants -> Target: They are students\n",
            "Input: Nous aimons la musique -> Target: We love music\n",
            "Input: Elle est heureuse -> Target: She is happy\n",
            "Input: Nous sommes amis -> Target: We are friends\n",
            "Input: Tu es fatigué -> Target: You are tired\n"
          ]
        }
      ]
    }
  ]
}